{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of Goals\n",
    "## Description\n",
    "We are investigatig a Kickstarter datatset that includes properties of Kickstarter campaigns starting from December 2016 until Janurary 2018. The dataset includes 378,000 projects.  The dataset includes the following key properties: \n",
    "    date the campaign was launched\n",
    "    the type of project\n",
    "    which country it was launch from\n",
    "    goal amount\n",
    "    number of backers\n",
    "    successful funding states\n",
    "    date of campaign closing\n",
    "    total amount pledged\n",
    "    \n",
    "We are looking for patterns of successfully funded projects among different projects. We want to see what characteristics of a project can help create high likelihood of being funded.\n",
    "## Importance of Problem\n",
    "Kickstarter is becoming an increasingly populat platform for startups. For new companies that cannot find or do not want Venture Capital funding or debt, Kickstarter provides an alternative for raising funds. Kickstarter helped kickoff a new era of \"Crowdfunding\", and continues to be the most popular crowdfunding platform for entrenpurs. We wanted to examine this dataset, because we want to help entrepenurs fund thier new company or product. A Kickstarter campaign takes a lot of time and money, and increasing numbers of people are turning to Kickstarter for funding. Therefore, if a company could know predict if their project would be successful or not before creating a campaign, they could find a better way of fundraising. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.359806607575\n",
      "[<function accuracy at 0x0000000015418B38>]\n"
     ]
    }
   ],
   "source": [
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "from patsy import dmatrices\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors, metrics, model_selection, naive_bayes\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# %pylab inline\n",
    "\n",
    "def is_currency(s):\n",
    "    '''Takes in an element of the series and outputs if it is a currency'''\n",
    "    return (s.isupper() and len(s) == 3)\n",
    "\n",
    "# Create the currency conversions for both pledged and goal\n",
    "# Conversion valid April 10, 2018 @ 12:00 PM Central Time\n",
    "currency_conversions = {\n",
    "    'USD': 1.000000,\n",
    "    'GBP': 1.41540,\n",
    "    'CAD': 0.793289,\n",
    "    'EUR': 1.23490,\n",
    "    'AUD': 0.776080,\n",
    "    'SEK': 0.120317,\n",
    "    'NZD': 0.736415,\n",
    "    'DKK': 0.165835,\n",
    "    'NOK': 0.128176,\n",
    "    'CHF': 1.04558,\n",
    "    'MXN': 0.0547386,\n",
    "    'SGD': 0.763829,\n",
    "    'HKD': 0.127393,\n",
    "    'JPY': 0.00931953\n",
    "}\n",
    "\n",
    "def currency_conversion(df):\n",
    "    '''Takes in an df and outputs the conversion'''\n",
    "    for k,v in currency_conversions.iteritems():\n",
    "        \n",
    "        # Create a make for the currency\n",
    "        mask_currency = (df['currency'] == k)\n",
    "        df.loc[mask_currency, 'usd_goal_current'] = df['goal'] * v\n",
    "        df.loc[mask_currency, 'usd_pledged_current'] = df['pledged']  * v\n",
    "    return df\n",
    "\n",
    "def clean_states(e):\n",
    "    '''Takes in an elements and returns if it is in a clean state'''\n",
    "    return (e in ['failed', 'successful', 'suspended', 'canceled'])\n",
    "\n",
    "\n",
    "def get_month(e):\n",
    "    '''Takes in a datetime element and returns the month'''\n",
    "    return e.month\n",
    "\n",
    "# Load the csv\n",
    "df = pd.read_csv('ks-projects-201801.csv')\n",
    "\n",
    "# Convert the currency into today's price\n",
    "df = currency_conversion(df)\n",
    "\n",
    "# Convert the deadline and launched columns into dtype: datetime\n",
    "df['deadline'] = pd.to_datetime(df['deadline'], format='%Y-%m-%d')\n",
    "df['launched'] = pd.to_datetime(df['launched'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Add a 'month' and 'year' coloumn to the df\n",
    "df['month_deadline'] = df['deadline'].map(get_month)\n",
    "df['month_launched'] = df['launched'].map(get_month)\n",
    "\n",
    "# Add an average pledge per backer\n",
    "df['average_pledged'] = df['pledged'] / df['backers']\n",
    "\n",
    "# Get a baseline for the ML\n",
    "# The first part is going to predict based off of cateogrical variables: \n",
    "# category, month-launched, month-deadline\n",
    "\n",
    "# There are 6 states: failed, successful, canceled, undefied, lived, suspended\n",
    "# For classification purposes 1.0 = successful, 0.0 = failed, suspended, canceled\n",
    "# Create a mask of just the clean states\n",
    "mask_clean_states = (df['state'].map(clean_states))\n",
    "df_clean_states = df[mask_clean_states]\n",
    "\n",
    "# Get the value counts for the clean states\n",
    "vc_clean_states = df_clean_states['state'].value_counts()\n",
    "\n",
    "# Find the baseline by dividing the total of project by the number of successful projects\n",
    "# baseline = 0.359806607575\n",
    "num_total_projects = vc_clean_states.sum()\n",
    "num_successful_projects = vc_clean_states['successful']\n",
    "baseline = float(num_successful_projects) / float(num_total_projects)\n",
    "\n",
    "# Create a dummy binary variable for success or fail/cancel/suspended\n",
    "df_clean_states['target'] = 0.0\n",
    "mask_target = df_clean_states['state'] == 'successful'\n",
    "df_clean_states.loc[mask_target, 'target'] = 1.0\n",
    "\n",
    "# Start with simple KNN with two features: Number of Backers and Goal Amount\n",
    "def accuracy(X, y, nn):\n",
    "\n",
    "    model = neighbors.KNeighborsClassifier(n_neighbors=nn, weights='uniform')\n",
    "    accuracies = []\n",
    "\n",
    "    kfold = model_selection.StratifiedKFold(n_splits=3, shuffle=True).split(X, y)\n",
    "    for train, holdout in kfold:\n",
    "        # Select the training and testing data using the indicies from kfold\n",
    "        X_train = X.iloc[train]\n",
    "        X_holdout = X.iloc[holdout]\n",
    "        y_train = y[train]\n",
    "        y_holdout = y[holdout]\n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Compute the accuracy\n",
    "        current_accuracy = metrics.accuracy_score(y_holdout, model.predict(X_holdout))\n",
    "        accuracies.append(current_accuracy)\n",
    "        \n",
    "    return accuracy\n",
    "\n",
    "'''\n",
    "# Create a design matrice\n",
    "Y, X = dmatrices('target ~ 0 + backers + usd_goal_real', df_clean_states, return_type='dataframe')\n",
    "y = Y['target'].values\n",
    "# sc = scatter(df_clean_states['backers'], df_clean_states['usd_goal_real'], c=y, cmap='bwr')\n",
    "\n",
    "\n",
    "# Create sample nn\n",
    "nn = [15]\n",
    "scores = [accuracy(X, y, num_nbrs) for num_nbrs in nn]\n",
    "print scores\n",
    "'''\n",
    "\n",
    "# Best Nearest Neighbor Numbers: Up to 100 nn they were all about the same accuracy between 91% and 93% \n",
    "# So you are best just using around 15 backers becuase it is faster\n",
    "# Starts to see small dips over 100 nn\n",
    "# Looks like the more backers and lower goal means that you have the best shot\n",
    "# But that makes sense, and is only after the fact\n",
    "# Backers is continuous not categorical\n",
    "\n",
    "# What about the category, main category, and goal amount\n",
    "# Can we predict if the project will be successfully funded\n",
    "# We first need to discretize the goal amount\n",
    "# Create 20 bins of the goal amount\n",
    "# usd_goal_real is discrete not catoegorical\n",
    "df['goal_binned'] = pd.qcut(df['usd_goal_real'], 10)\n",
    "\n",
    "# Create a list of categorical columns that will be used\n",
    "categorical_columns = ['goal_binned', 'category', 'main_category']\n",
    "\n",
    "# Create a df that includes the dummy variables\n",
    "df_dummies = pd.get_dummies(df[categorical_columns], prefix=categorical_columns, columns=categorical_columns)\n",
    "df\n",
    "\n",
    "\n",
    "# Maybe use the test data for the live ones?\n",
    "\n",
    "\n",
    "# Possible Features:\n",
    "# Month launched and deadline\n",
    "# Goal Amount\n",
    "# Number of Backers\n",
    "# Country of Origin\n",
    "# Category and Main Category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution and insights\n",
    "Our problem, is a classification problem. We want to use certain features of a Kickstarter Campaign to determine if the campagin was successful or not. We first had to clean the data and convert the columns into proper datetime objects. We then got our baseline for the dataset, which was 0.35891\n",
    "\n",
    "In the dataset there is a feature titled \"state\", which says the status of the project. There are six possible states, but we are only concerned with four of them: successful, failed, canceled, and suspended. Our first approach was to use a k-Nearest-Neighbors (kNN) classifer to make predictions. In our approach we created a new target column and assigned a binary value. 1.0 was assigned for successful projects, and 0.0 was assinged for the other three states. \n",
    "\n",
    "In our first attempt we chose two features: number of backers and target goal converted to USD according to the date of the project launch. We used cross-validation to determine the optimal number of nearest-neighbors. Surpringly, the number of nearest-neighbors for numbers under 100 has about the same accuracy. It ranged from 91% to 93% accurate. Increasing the number of nearest neighbors more than 100 say decreased accuracy. \n",
    "\n",
    "(graph) Although we had really high accuracy with this kNN classifer, analyzing the model shows it is not the best option. Looking at the graph, you can see that there are two clusters of projects. Those with high backers and lower goals that succeeded, and those with little backers and higher goals that failed. This classifer is fairly intuitive and relies on data from after the project has finished. Since we want to help future Kickstarter project, we felt that we could do better.\n",
    "\n",
    "Since most of the data seems independent, the Naive-Bayes classifer seemed like a better choice. There is a correlation between category/main category and goal, with different categories having higher average goals. However, there is a wide spread of goals in each category and therefore it is hard to true determine how dependent the variables are. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
