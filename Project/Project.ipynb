{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of Goals\n",
    "## Description\n",
    "We are investigatig a Kickstarter datatset that includes properties of Kickstarter campaigns starting from December 2016 until Janurary 2018. The dataset includes 378,000 projects.  The dataset includes the following key properties: \n",
    "    date the campaign was launched\n",
    "    the type of project\n",
    "    which country it was launch from\n",
    "    goal amount\n",
    "    number of backers\n",
    "    successful funding states\n",
    "    date of campaign closing\n",
    "    total amount pledged\n",
    "    \n",
    "We are looking for patterns of successfully funded projects among different projects. We want to see what characteristics of a project can help create high likelihood of being funded.\n",
    "## Importance of Problem\n",
    "Kickstarter is becoming an increasingly populat platform for startups. For new companies that cannot find or do not want Venture Capital funding or debt, Kickstarter provides an alternative for raising funds. Kickstarter helped kickoff a new era of \"Crowdfunding\", and continues to be the most popular crowdfunding platform for entrenpurs. We wanted to examine this dataset, because we want to help entrepenurs fund thier new company or product. A Kickstarter campaign takes a lot of time and money, and increasing numbers of people are turning to Kickstarter for funding. Therefore, if a company could know predict if their project would be successful or not before creating a campaign, they could find a better way of fundraising. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tracetschida\\Anaconda2\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "22\n",
      "100000000.0\n",
      "20338986.27\n",
      "166361390.71\n"
     ]
    }
   ],
   "source": [
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "from patsy import dmatrices\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn import neighbors, metrics, model_selection, naive_bayes, tree\n",
    "from datetime import datetime\n",
    "from numpy import exp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%pylab inline\n",
    "\n",
    "def is_currency(s):\n",
    "    '''Takes in an element of the series and outputs if it is a currency'''\n",
    "    return (s.isupper() and len(s) == 3)\n",
    "\n",
    "# Create the currency conversions for both pledged and goal\n",
    "# Conversion valid April 10, 2018 @ 12:00 PM Central Time\n",
    "currency_conversions = {\n",
    "    'USD': 1.000000,\n",
    "    'GBP': 1.41540,\n",
    "    'CAD': 0.793289,\n",
    "    'EUR': 1.23490,\n",
    "    'AUD': 0.776080,\n",
    "    'SEK': 0.120317,\n",
    "    'NZD': 0.736415,\n",
    "    'DKK': 0.165835,\n",
    "    'NOK': 0.128176,\n",
    "    'CHF': 1.04558,\n",
    "    'MXN': 0.0547386,\n",
    "    'SGD': 0.763829,\n",
    "    'HKD': 0.127393,\n",
    "    'JPY': 0.00931953\n",
    "}\n",
    "\n",
    "def currency_conversion(df):\n",
    "    '''Takes in an df and outputs the conversion'''\n",
    "    for k,v in currency_conversions.iteritems():\n",
    "        \n",
    "        # Create a make for the currency\n",
    "        mask_currency = (df['currency'] == k)\n",
    "        df.loc[mask_currency, 'usd_goal_current'] = df['goal'] * v\n",
    "        df.loc[mask_currency, 'usd_pledged_current'] = df['pledged']  * v\n",
    "    return df\n",
    "\n",
    "def clean_states(e):\n",
    "    '''Takes in an elements and returns if it is in a clean state'''\n",
    "    return (e in ['failed', 'successful', 'suspended', 'canceled'])\n",
    "\n",
    "\n",
    "def get_month(e):\n",
    "    '''Takes in a datetime element and returns the month'''\n",
    "    return e.month\n",
    "\n",
    "def name_month(e):\n",
    "    '''Takes in an element from a series, and outputs the \n",
    "    string representation of the month'''\n",
    "\n",
    "    month = int(e)\n",
    "    return months[month]\n",
    "\n",
    "months = {\n",
    "    1: 'January',\n",
    "    2: 'February',\n",
    "    3: 'March',\n",
    "    4: 'April',\n",
    "    5: 'May',\n",
    "    6: 'June',\n",
    "    7: 'July',\n",
    "    8: 'August',\n",
    "    9: 'September',\n",
    "    10: 'October',\n",
    "    11: 'November',\n",
    "    12: 'December'\n",
    "}\n",
    "\n",
    "def get_days(e):\n",
    "    '''Takes in a DateTime element from a series and \n",
    "    returns the number of days'''\n",
    "    return e.days\n",
    "\n",
    "# Load the csv\n",
    "df = pd.read_csv('ks-projects-201801.csv')\n",
    "\n",
    "# Drop countries with name N,0\"\n",
    "mask_country_drop = (df['country'] != 'N,0\"')\n",
    "df = df[mask_country_drop]\n",
    "\n",
    "print len(df['country'].value_counts())\n",
    "print df['goal'].max()\n",
    "print df['usd_pledged_real'].max()\n",
    "print df['usd_goal_real'].max()\n",
    "\n",
    "# Convert the currency into today's price\n",
    "df = currency_conversion(df)\n",
    "\n",
    "# Convert the deadline and launched columns into dtype: datetime\n",
    "df['deadline'] = pd.to_datetime(df['deadline'], format='%Y-%m-%d')\n",
    "df['launched'] = pd.to_datetime(df['launched'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Add a 'month' and 'year' coloumn to the df\n",
    "df['month_deadline'] = df['deadline'].map(get_month)\n",
    "df['month_launched'] = df['launched'].map(get_month)\n",
    "\n",
    "# Add an average pledge per backer\n",
    "df['average_pledged'] = df['pledged'] / df['backers']\n",
    "\n",
    "# Create a cateogy for the month launched, goals, and quarter launched\n",
    "df['month_named'] = df['month_launched'].map(name_month).astype('category')\n",
    "\n",
    "# Bin goal amount\n",
    "df['goal_binned'] = pd.qcut(df['usd_goal_real'], 10)\n",
    "\n",
    "# Bin the months into quarters\n",
    "df['quarter_binned'] = \"Q1\"\n",
    "mask_q1 = (df['month_launched'] <= 3)\n",
    "mask_q2 = ((df['month_launched'] > 3) & (df['month_launched'] <= 6))\n",
    "mask_q3 = ((df['month_launched'] > 6) & (df['month_launched'] <= 9))\n",
    "mask_q4 = (df['month_launched'] > 9)\n",
    "\n",
    "df.loc[mask_q1, 'quarter_binned'] = \"Q1\"\n",
    "df.loc[mask_q2, 'quarter_binned'] = \"Q2\"\n",
    "df.loc[mask_q3, 'quarter_binned'] = \"Q3\"\n",
    "df.loc[mask_q4, 'quarter_binned'] = \"Q4\"\n",
    "df['quarter_binned'] = df['quarter_binned'].astype('category')\n",
    "\n",
    "# Get the length of the project\n",
    "df['project_length'] = df['deadline'] - df['launched']\n",
    "df['project_length_days'] = df['project_length'].map(get_days)\n",
    "df['project_length_days_binned'] = pd.qcut(df['project_length_days'], 3)\n",
    "# print df['project_length_days'].value_counts()\n",
    "\n",
    "# Get a baseline for the ML\n",
    "# The first part is going to predict based off of cateogrical variables: \n",
    "# category, month-launched, month-deadline\n",
    "\n",
    "# There are 6 states: failed, successful, canceled, undefied, lived, suspended\n",
    "# For classification purposes 1.0 = successful, 0.0 = failed, suspended, canceled\n",
    "# Create a mask of just the clean states\n",
    "mask_clean_states = (df['state'].map(clean_states))\n",
    "df_clean_states = df[mask_clean_states]\n",
    "\n",
    "# Get the value counts for the clean states\n",
    "vc_clean_states = df_clean_states['state'].value_counts()\n",
    "\n",
    "# Find the baseline by dividing the total of project by the number of successful projects\n",
    "# baseline = 0.359806607575\n",
    "num_total_projects = vc_clean_states.sum()\n",
    "num_successful_projects = vc_clean_states['successful']\n",
    "baseline = float(num_successful_projects) / float(num_total_projects)\n",
    "\n",
    "# Create a dummy binary variable for success or fail/cancel/suspended\n",
    "df_clean_states['target'] = 0.0\n",
    "mask_target = df_clean_states['state'] == 'successful'\n",
    "df_clean_states.loc[mask_target, 'target'] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory\n",
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 ID          goal       pledged        backers   usd pledged  \\\n",
      "count  3.720660e+05  3.720660e+05  3.720660e+05  372066.000000  3.720660e+05   \n",
      "mean   1.074579e+09  4.931812e+04  9.755414e+03     106.977278  7.080215e+03   \n",
      "std    6.191861e+08  1.182568e+06  9.626515e+04     914.519327  7.893105e+04   \n",
      "min    5.971000e+03  1.000000e-02  0.000000e+00       0.000000  0.000000e+00   \n",
      "25%    5.378122e+08  2.000000e+03  3.100000e+01       2.000000  1.800000e+01   \n",
      "50%    1.075289e+09  5.500000e+03  6.250000e+02      12.000000  4.000000e+02   \n",
      "75%    1.610135e+09  1.650000e+04  4.092972e+03      57.000000  3.056957e+03   \n",
      "max    2.147476e+09  1.000000e+08  2.033899e+07  219382.000000  2.033899e+07   \n",
      "\n",
      "       usd_pledged_real  usd_goal_real  usd_goal_current  usd_pledged_current  \\\n",
      "count      3.720660e+05   3.720660e+05      3.720660e+05         3.720660e+05   \n",
      "mean       9.145240e+03   4.573770e+04      4.575658e+04         9.164273e+03   \n",
      "std        9.162097e+04   1.151682e+06      1.146697e+06         9.181090e+04   \n",
      "min        0.000000e+00   1.000000e-02      1.000000e-02         0.000000e+00   \n",
      "25%        3.124000e+01   2.000000e+03      2.000000e+03         3.100000e+01   \n",
      "50%        6.275900e+02   5.500000e+03      5.500000e+03         6.274558e+02   \n",
      "75%        4.066000e+03   1.600000e+04      1.586578e+04         4.070008e+03   \n",
      "max        2.033899e+07   1.663614e+08      1.415400e+08         2.033899e+07   \n",
      "\n",
      "       month_deadline  month_launched  average_pledged  \\\n",
      "count   372066.000000   372066.000000     3.208050e+05   \n",
      "mean         6.766106        6.428147              inf   \n",
      "std          3.318670        3.307758              NaN   \n",
      "min          1.000000        1.000000     1.000000e+00   \n",
      "25%          4.000000        4.000000     2.500000e+01   \n",
      "50%          7.000000        6.000000     4.821429e+01   \n",
      "75%         10.000000        9.000000     8.539560e+01   \n",
      "max         12.000000       12.000000              inf   \n",
      "\n",
      "                project_length  project_length_days         target  \n",
      "count                   372066        372066.000000  372066.000000  \n",
      "mean   33 days 21:24:33.703638            33.457763       0.359751  \n",
      "std    66 days 11:21:27.071299            66.469087       0.479928  \n",
      "min            0 days 00:07:17             0.000000       0.000000  \n",
      "25%           29 days 02:19:17            29.000000       0.000000  \n",
      "50%           29 days 16:26:58            29.000000       0.000000  \n",
      "75%    36 days 08:38:46.250000            36.000000       1.000000  \n",
      "max        16738 days 23:00:00         16738.000000       1.000000  \n"
     ]
    }
   ],
   "source": [
    "print df_clean_states.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Month with the most funding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month_named\n",
      "May          3.376397e+08\n",
      "October      3.291367e+08\n",
      "July         3.230421e+08\n",
      "November     3.225258e+08\n",
      "September    3.208969e+08\n",
      "March        3.194561e+08\n",
      "June         2.991560e+08\n",
      "April        2.953899e+08\n",
      "February     2.683136e+08\n",
      "August       2.498201e+08\n",
      "January      2.099652e+08\n",
      "December     1.272905e+08\n",
      "Name: usd_pledged_real, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "series_month_pledges = df_clean_states.groupby('month_named')['usd_pledged_real'].sum().sort_values(ascending=False)\n",
    "print series_month_pledges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized by Number of projects in the Month with Most funding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "September    10429.906859\n",
      "May          10339.919962\n",
      "November     10071.693120\n",
      "October       9921.525420\n",
      "March         9533.156407\n",
      "April         9275.865542\n",
      "June          9228.938105\n",
      "February      9144.977784\n",
      "July          8949.775513\n",
      "August        7807.121433\n",
      "January       7669.682215\n",
      "December      6099.795468\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "series_projects_by_month = df_clean_states['month_named'].value_counts()\n",
    "print (series_month_pledges / series_projects_by_month).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Month with the highest average pledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month_named\n",
      "November     92.254616\n",
      "July         90.864384\n",
      "September    88.595124\n",
      "June         87.685429\n",
      "May          87.070327\n",
      "March        86.783788\n",
      "February     85.230209\n",
      "October      84.354008\n",
      "April        84.190834\n",
      "December     81.239821\n",
      "August       78.985250\n",
      "January      73.145615\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "series_month_backers = df_clean_states.groupby('month_named')['backers'].sum()\n",
    "print (series_month_pledges / series_month_backers).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which Category had the most funding, and backers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "Product Design    6.317889e+08\n",
      "Tabletop Games    4.627050e+08\n",
      "Video Games       2.159422e+08\n",
      "Hardware          1.547575e+08\n",
      "Technology        1.414238e+08\n",
      "Documentary       1.387923e+08\n",
      "Gadgets           8.961746e+07\n",
      "Design            7.322612e+07\n",
      "Food              7.038465e+07\n",
      "Wearables         6.777069e+07\n",
      "Name: usd_pledged_real, dtype: float64\n",
      "\n",
      "Camera Equipment     82131.895922\n",
      "3D Printing          67167.217789\n",
      "Sound                62970.574733\n",
      "Wearables            56008.837669\n",
      "Fabrication Tools    48963.159512\n",
      "Hardware             42550.857094\n",
      "Gaming Hardware      40456.838278\n",
      "Tabletop Games       32885.930691\n",
      "Robots               32784.924499\n",
      "Space Exploration    30897.758625\n",
      "dtype: float64\n",
      "\n",
      "category\n",
      "Product Design    6114407\n",
      "Tabletop Games    6033518\n",
      "Video Games       4413555\n",
      "Documentary       1446302\n",
      "Technology        1148594\n",
      "Hardware          1128570\n",
      "Gadgets            923100\n",
      "Music              862686\n",
      "Food               764749\n",
      "Design             752692\n",
      "Name: backers, dtype: int64\n",
      "\n",
      "Chiptune             443.942857\n",
      "Camera Equipment     436.262136\n",
      "Tabletop Games       428.821464\n",
      "Wearables            382.538843\n",
      "Video Games          375.845610\n",
      "Sound                365.007634\n",
      "Gadgets              316.238438\n",
      "Space Exploration    311.131250\n",
      "Hardware             310.302447\n",
      "Typography           291.650943\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = df_clean_states.copy()\n",
    "series_categories_pledged = df.groupby('category')['usd_pledged_real'].sum().sort_values(ascending=False)[:10]\n",
    "print series_categories_pledged\n",
    "print \n",
    "\n",
    "series_cat_pledged_norm = (df.groupby('category')['usd_pledged_real'].sum() / df['category']\\\n",
    "                           .value_counts()).sort_values(ascending=False)[:10]\n",
    "print series_cat_pledged_norm\n",
    "print\n",
    "\n",
    "series_categories_backers = df.groupby('category')['backers'].sum().sort_values(ascending=False)[:10]\n",
    "print series_categories_backers\n",
    "print\n",
    "\n",
    "series_cat_backers_norm = (df.groupby('category')['backers'].sum() / df['category']\\\n",
    "                           .value_counts()).sort_values(ascending=False)[:10]\n",
    "print series_cat_backers_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which Main Category had the most funding and backers (normilzed too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main_category\n",
      "Games           7.398133e+08\n",
      "Design          7.285961e+08\n",
      "Technology      6.811603e+08\n",
      "Film & Video    3.893949e+08\n",
      "Music           1.928839e+08\n",
      "Publishing      1.327654e+08\n",
      "Fashion         1.297762e+08\n",
      "Food            1.251628e+08\n",
      "Art             9.021672e+07\n",
      "Comics          7.133717e+07\n",
      "Name: usd_pledged_real, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "series_maincat_pledged = df.groupby('main_category')['usd_pledged_real'].sum().sort_values(ascending=False)[:10]\n",
    "print series_maincat_pledged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution and insights\n",
    "## KNN\n",
    "Our problem, is a classification problem. We want to use certain features of a Kickstarter Campaign to determine if the campagin was successful or not. We first had to clean the data and convert the columns into proper datetime objects. We then got our baseline for the dataset, which is 63.55% for only picking that a project will not get funding.\n",
    "\n",
    "In the dataset there is a feature titled \"state\", which says the status of the project. There are six possible states, but we are only concerned with four of them: successful, failed, canceled, and suspended. Our first approach was to use a k-Nearest-Neighbors (kNN) classifer to make predictions. In our approach we created a new target column and assigned a binary value. 1.0 was assigned for successful projects, and 0.0 was assinged for the other three states. \n",
    "\n",
    "In our first attempt we chose two features: number of backers and target goal converted to USD according to the date of the project launch. We used cross-validation to determine the optimal number of nearest-neighbors. Surpringly, the number of nearest-neighbors for numbers under 100 has about the same accuracy. It ranged from 91% to 93% accurate. Increasing the number of nearest neighbors more than 100 say decreased accuracy. \n",
    "\n",
    "(graph) Although we had really high accuracy with this kNN classifer, analyzing the model shows it is not the best option. We originally thought knowing the how many backers you need compared to your goal would help you determine how to run your project. Looking at the graph, you can see that there are two clusters of projects. Those with high backers and lower goals that succeeded, and those with little backers and higher goals that failed. This classifer is fairly intuitive and relies on data from after the project has finished. Since we want to help future Kickstarter projects. We felt that we could do better using data before the project is launched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with simple KNN with two features: Number of Backers and Goal Amount\n",
    "def accuracy(X, y, nn):\n",
    "\n",
    "    model = neighbors.KNeighborsClassifier(n_neighbors=nn, weights='uniform')\n",
    "    accuracies = []\n",
    "\n",
    "    kfold = model_selection.StratifiedKFold(n_splits=3, shuffle=True).split(X, y)\n",
    "    for train, holdout in kfold:\n",
    "        # Select the training and testing data using the indicies from kfold\n",
    "        X_train = X.iloc[train]\n",
    "        X_holdout = X.iloc[holdout]\n",
    "        y_train = y[train]\n",
    "        y_holdout = y[holdout]\n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Compute the accuracy\n",
    "        current_accuracy = metrics.accuracy_score(y_holdout, model.predict(X_holdout))\n",
    "        accuracies.append(current_accuracy)\n",
    "        \n",
    "    return accuracies\n",
    "\n",
    "# Create sample nn\n",
    "nn = [15]\n",
    "scores = [accuracy(X, y, num_nbrs) for num_nbrs in nn]\n",
    "print scores\n",
    "\n",
    "# Create a design matrice\n",
    "Y, X = dmatrices('target ~ 0 + backers + usd_goal_real', df_clean_states, return_type='dataframe')\n",
    "y = Y['target'].values\n",
    "sc = scatter(df_clean_states['backers'], df_clean_states['usd_goal_real'], c=y, cmap='bwr')\n",
    "xlabel('number of backers')\n",
    "ylabel('goal USD')\n",
    "savefig('backers_goal.png')\n",
    "\n",
    "pd.options.display.max_colwidth = 50\n",
    "print df_clean_states[['backers', 'name']].sort_values(ascending=False, axis=0, by=['backers'])[:10]\n",
    "print df_clean_states[['usd_goal_real', 'name']].sort_values(ascending=False, axis=0, by=['usd_goal_real'])[:10]\n",
    "\n",
    "# Best Nearest Neighbor Numbers: Up to 100 nn they were all about the same accuracy between 91% and 93% \n",
    "# So you are best just using around 15 backers becuase it is faster\n",
    "# Starts to see small dips over 100 nn\n",
    "# Looks like the more backers and lower goal means that you have the best shot\n",
    "# But that makes sense, and is only after the fact\n",
    "# Backers is continuous not categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "Since most of the data seems independent and categorical, the Naive-Bayes classifer seemed like a better choice. There is a correlation between category/main category and goal (figure), with different categories having higher average goals. However, there is a wide spread of goals in each category and therefore it is hard to true determine how dependent the variables are. \n",
    "\n",
    "We created five categorical parameters: goal amounts in 10 bins, length of fundraising in three bins, category, country, and the quarter the project was started. The three bins for the length are less than 29 days, between 29 and 31 days, and over 31 days. With most of the data between 29 and 31 days.\n",
    "\n",
    "With the Naive Bayes model we were able to get 68.92% accuracy. This is only slighty higher than the baseline of 63.55%. The class priors are slightly different than the baseline we predicted but not too much. Looking at the feature importance gives us further insight to what makes a Kickstarter project successful. 9 out of the 10 top important features are categories, and 4 of the featuers belong to the main category of technology. The only other non-category feature is the goal binned. This shows that the projects with reasonable funding goals get are important in this model for project successfulness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about the category, main category, country, month launched, and goal amount\n",
    "# Can we predict if the project will be successfully funded\n",
    "# We first need to discretize the goal amount\n",
    "# Create 20 bins of the goal amount\n",
    "# usd_goal_real is discrete not catoegorical\n",
    "def accuracy_nb(X, y, splits, model):\n",
    "    \n",
    "    accuracies = []\n",
    "\n",
    "    kfold = model_selection.StratifiedKFold(n_splits=splits, shuffle=True).split(X, y)\n",
    "    for train, holdout in kfold:\n",
    "        # Select the training and testing data using the indicies from kfold\n",
    "        X_train = X.iloc[train]\n",
    "        X_holdout = X.iloc[holdout]\n",
    "        y_train = y[train]\n",
    "        y_holdout = y[holdout]\n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Compute the accuracy\n",
    "        current_accuracy = metrics.accuracy_score(y_holdout, model.predict(X_holdout))\n",
    "        accuracies.append(current_accuracy)\n",
    "        \n",
    "    return accuracies\n",
    "\n",
    "# Create a list of categorical columns that will be used\n",
    "categorical_columns = ['goal_binned', 'category',\n",
    "'country', 'quarter_binned', 'project_length_days_binned']\n",
    "\n",
    "print df_clean_states['project_length_days_binned'].value_counts()\n",
    "\n",
    "# Create a df that includes the dummy variables (0/1) for all categorical data\n",
    "df_dummies = pd.get_dummies(df_clean_states[categorical_columns],\n",
    "prefix=categorical_columns,columns=categorical_columns)\n",
    "\n",
    "# Concatenate all dummy columns into the dataframe\n",
    "df_clean_dummies = pd.concat([df_clean_states, df_dummies], axis=1)\n",
    "\n",
    "# Create the formula\n",
    "formula = 'target ~ 0 + {}'.format(' + '.join(['Q(\"{}\")'.format(x) for x in df_dummies.columns.values[:205]]))\n",
    "\n",
    "# Create the testings and training matrices\n",
    "Y,X = dmatrices(formula, df_clean_dummies, return_type='dataframe')\n",
    "y = Y['target'].values\n",
    "    \n",
    "# Build and run the model\n",
    "model = naive_bayes.MultinomialNB()\n",
    "accuracies = accuracy_nb(X, y, 3, model)\n",
    "print accuracies\n",
    "\n",
    "# Get the class priors\n",
    "print 'Negative Class Prior'\n",
    "print exp(model.class_log_prior_[0])\n",
    "print 'Positive Class Prior'\n",
    "print exp(model.class_log_prior_[1])\n",
    "\n",
    "# Check class priors\n",
    "print\n",
    "print 'Check class priors'\n",
    "print df_clean_dummies['target'].value_counts() / len(df)\n",
    "\n",
    "# Check the likelihood and feature importance\n",
    "# Seems like technology categories are the most important...\n",
    "feature_importance = abs(model.feature_log_prob_[1] - model.feature_log_prob_[0])\n",
    "series_feature_importance = Series(feature_importance, index=X.columns.values)\n",
    "print series_feature_importance.sort_values(ascending=False)[:10]\n",
    "\n",
    "# Need to build up cross validation\n",
    "\n",
    "# Get the categories with the most funding\n",
    "temp = df.groupby('main_category')['usd_goal_real'].mean().sort_values(ascending=False)\n",
    "print temp\n",
    "\n",
    "\n",
    "# Maybe use the test data for the live ones?\n",
    "\n",
    "\n",
    "# Possible Features:\n",
    "# Month launched and deadline\n",
    "# Goal Amount\n",
    "# Number of Backers\n",
    "# Country of Origin\n",
    "# Category and Main Category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "After cross-validating the depth of the tree, 5 levels seemed to provide the best balance of small depth and higher accuracy. Unfortunately, the accuracy was only slightly above the baseline, 66.09% versus 63.55. This is not a significant jump to be able to predict if a project will be successful or not. Looking at the tree (figure), the project Length in days and the goal amount are the most important features of the decision tree as they make up the first three levels. \n",
    "\n",
    "This is very different than the important feature from Naives Bayes. Most of the important feature from Naive Bayes were the categories of the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the design matrices\n",
    "print df_clean_states.columns.values\n",
    "Y, X = dmatrices('target ~ 0 + usd_goal_real + category + main_category + \\\n",
    "country + month_named + project_length_days', df_clean_states, return_type='dataframe')\n",
    "y = Y['target'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# Create the splits in the dataset\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "\n",
    "# Iterate over max_depth\n",
    "for max_depth in [5]:\n",
    "    model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=max_depth)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "    print scores.mean()\n",
    "    \n",
    "model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=5)\n",
    "model.fit(X_train, y_train)\n",
    "print metrics.accuracy_score(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import StringIO\n",
    "import pydot_ng\n",
    "dot_data = StringIO.StringIO()\n",
    "tree.export_graphviz(model, out_file=dot_data, feature_names=X.columns.values)\n",
    "pydot_ng.graph_from_dot_data(dot_data.getvalue()).write_png('tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
